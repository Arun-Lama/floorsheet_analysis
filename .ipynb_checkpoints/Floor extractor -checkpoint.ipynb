{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3c0b535-0457-44f8-9ea7-569bb88b2ee4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-02-17 20:00:22.757726\n",
      "Set Limit = 500\n",
      "Number of Pages = 206\n",
      "Page: 1\n",
      "Page: 2\n",
      "Page: 3\n",
      "Page: 4\n",
      "Page: 5\n",
      "Page: 6\n",
      "Page: 7\n",
      "Page: 8\n",
      "Page: 9\n",
      "Page: 10\n",
      "Page: 11\n",
      "Page: 12\n",
      "Page: 13\n",
      "Page: 14\n",
      "Page: 15\n",
      "Page: 16\n",
      "Page: 17\n",
      "Page: 18\n",
      "Page: 19\n",
      "Page: 20\n",
      "Page: 21\n",
      "Page: 22\n",
      "Page: 23\n",
      "Page: 24\n",
      "Page: 25\n",
      "Page: 26\n",
      "Page: 27\n",
      "Page: 28\n",
      "Page: 29\n",
      "Page: 30\n",
      "Page: 31\n",
      "Page: 32\n",
      "Page: 33\n",
      "Page: 34\n",
      "Page: 35\n",
      "Page: 36\n",
      "Page: 37\n",
      "Page: 38\n",
      "Page: 39\n",
      "Page: 40\n",
      "Page: 41\n",
      "Page: 42\n",
      "Page: 43\n",
      "Page: 44\n",
      "Page: 45\n",
      "Page: 46\n",
      "Page: 47\n",
      "Page: 48\n",
      "Page: 49\n",
      "Page: 50\n",
      "Page: 51\n",
      "Page: 52\n",
      "Page: 53\n",
      "Page: 54\n",
      "Page: 55\n",
      "Page: 56\n",
      "Page: 57\n",
      "Page: 58\n",
      "Page: 59\n",
      "Page: 60\n",
      "Page: 61\n",
      "Page: 62\n",
      "Page: 63\n",
      "Page: 64\n",
      "Page: 65\n",
      "Page: 66\n",
      "Page: 67\n",
      "Page: 68\n",
      "Page: 69\n",
      "Page: 70\n",
      "Page: 71\n",
      "Page: 72\n",
      "Page: 73\n",
      "Page: 74\n",
      "Page: 75\n",
      "Page: 76\n",
      "Page: 77\n",
      "Page: 78\n",
      "Page: 79\n",
      "Page: 80\n",
      "Page: 81\n",
      "Page: 82\n",
      "Page: 83\n",
      "Page: 84\n",
      "Page: 85\n",
      "Page: 86\n",
      "Page: 87\n",
      "Page: 88\n",
      "Page: 89\n",
      "Page: 90\n",
      "Page: 91\n",
      "Page: 92\n",
      "Page: 93\n",
      "Page: 94\n",
      "Page: 95\n",
      "Page: 96\n",
      "Page: 97\n",
      "Page: 98\n",
      "Page: 99\n",
      "Page: 100\n",
      "Page: 101\n",
      "Page: 102\n",
      "Page: 103\n",
      "Page: 104\n",
      "Page: 105\n",
      "Page: 106\n",
      "Page: 107\n",
      "Page: 108\n",
      "Page: 109\n",
      "Page: 110\n",
      "Page: 111\n",
      "Page: 112\n",
      "Page: 113\n",
      "Page: 114\n",
      "Page: 115\n",
      "Page: 116\n",
      "Page: 117\n",
      "Page: 118\n",
      "Page: 119\n",
      "Page: 120\n",
      "Page: 121\n",
      "Page: 122\n",
      "Page: 123\n",
      "Page: 124\n",
      "Page: 125\n",
      "Page: 126\n",
      "Page: 127\n",
      "Page: 128\n",
      "Page: 129\n",
      "Page: 130\n",
      "Page: 131\n",
      "Page: 132\n",
      "Page: 133\n",
      "Page: 134\n",
      "Page: 135\n",
      "Page: 136\n",
      "Page: 137\n",
      "Page: 138\n",
      "Page: 139\n",
      "Page: 140\n",
      "Page: 141\n",
      "Page: 142\n",
      "Page: 143\n",
      "Page: 144\n",
      "Page: 145\n",
      "Page: 146\n",
      "Page: 147\n",
      "Page: 148\n",
      "Page: 149\n",
      "Page: 150\n",
      "Page: 151\n",
      "Page: 152\n",
      "Page: 153\n",
      "Page: 154\n",
      "Page: 155\n",
      "Page: 156\n",
      "Page: 157\n",
      "Page: 158\n",
      "Page: 159\n",
      "Page: 160\n",
      "Page: 161\n",
      "Page: 162\n",
      "Page: 163\n",
      "Page: 164\n",
      "Page: 165\n",
      "Page: 166\n",
      "Page: 167\n",
      "Page: 168\n",
      "Page: 169\n",
      "Page: 170\n",
      "Page: 171\n",
      "Page: 172\n",
      "Page: 173\n",
      "Page: 174\n",
      "Page: 175\n",
      "Page: 176\n",
      "Page: 177\n",
      "Page: 178\n",
      "Page: 179\n",
      "Page: 180\n",
      "Page: 181\n",
      "Page: 182\n",
      "Page: 183\n",
      "Page: 184\n",
      "Page: 185\n",
      "Page: 186\n",
      "Page: 187\n",
      "Page: 188\n",
      "Page: 189\n",
      "Page: 190\n",
      "Page: 191\n",
      "Page: 192\n",
      "Page: 193\n",
      "Page: 194\n",
      "Page: 195\n",
      "Page: 196\n",
      "Page: 197\n",
      "Page: 198\n",
      "Page: 199\n",
      "Page: 200\n",
      "Page: 201\n",
      "Page: 202\n",
      "Page: 203\n",
      "Page: 204\n",
      "Page: 205\n",
      "Page: 206\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'date' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 82\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Concatenate the dataframes in the list into a single dataframe\u001b[39;00m\n\u001b[0;32m     81\u001b[0m all_floorsheet_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(all_floorsheet_data, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 82\u001b[0m date_format \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(date, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm/\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     83\u001b[0m all_floorsheet_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m date_format\n\u001b[0;32m     84\u001b[0m all_floorsheet_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContract No.\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_floorsheet_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContract No.\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'date' is not defined"
     ]
    }
   ],
   "source": [
    "# Working Good.\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import datetime\n",
    "\n",
    "# Print current date and time\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "# Set the URL and output file path\n",
    "base_url = \"https://nepalstock.com/floor-sheet?&symbol=&floor=1&startDate=&endDate=&_limit=\"\n",
    "output_file_path = \"F:/Floorsheet Data/FloorsheetData1.csv\"\n",
    "\n",
    "# Clear the contents of the output file if it exists\n",
    "if os.path.exists(output_file_path):\n",
    "    with open(output_file_path, 'w') as file:\n",
    "        file.write(\"\")\n",
    "\n",
    "# Set up Selenium WebDriver with Chrome options\n",
    "options = Options()\n",
    "options.headless = True  # Enable headless mode\n",
    "driver = webdriver.Chrome(options=options)\n",
    "\n",
    "# Open the webpage\n",
    "driver.get(base_url)\n",
    "\n",
    "# Set limit\n",
    "select_element = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.XPATH, \"/html/body/app-root/div/main/div/app-floor-sheet/div/div[3]/div/div[5]/div/select/option[6]\"))\n",
    ")\n",
    "select_element.click()\n",
    "limit_set = select_element.text\n",
    "print(\"Set Limit =\", limit_set)\n",
    "\n",
    "# Click Filter button\n",
    "filter_button = WebDriverWait(driver, 10).until(\n",
    "    EC.element_to_be_clickable((By.XPATH, \"/html/body/app-root/div/main/div/app-floor-sheet/div/div[3]/div/div[6]/button[1]\"))\n",
    ")\n",
    "filter_button.click()\n",
    "time.sleep(3)  # Wait for the page to load\n",
    "\n",
    "# Extract number of pages\n",
    "try:\n",
    "    num_pages_element = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.XPATH, '/html/body/app-root/div/main/div/app-floor-sheet/div/div[5]/div[2]/pagination-controls/pagination-template/ul/li[9]/a/span[2]'))\n",
    "    )\n",
    "    num_pages = int(num_pages_element.text)\n",
    "except:\n",
    "    # In case the XPath is still incorrect or changes, print an error and set a default value for number of pages\n",
    "    print(\"Could not locate the number of pages element.\")\n",
    "    num_pages = 1  # Default to 1 page if unable to determine the actual number\n",
    "print(\"Number of Pages =\", num_pages)\n",
    "\n",
    "# Initialize an empty list to store all the pages' data\n",
    "all_floorsheet_data = []\n",
    "\n",
    "# Loop through pages and extract data\n",
    "for page in range(1, num_pages + 1):\n",
    "    # Extract the table data using Pandas\n",
    "    dfs = pd.read_html(StringIO(driver.page_source))\n",
    "    floorsheet_data = dfs[0]\n",
    "\n",
    "    # Append the current page's data to the overall data list\n",
    "    all_floorsheet_data.append(floorsheet_data)\n",
    "    print(\"Page:\", page)\n",
    "# Navigate to the next page if not on the last page\n",
    "    if page < num_pages:\n",
    "        next_button = WebDriverWait(driver, 10).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, \"/html/body/app-root/div/main/div/app-floor-sheet/div/div[5]/div[2]/pagination-controls/pagination-template/ul/li[10]/a\"))\n",
    "        )\n",
    "        next_button.click()\n",
    "        time.sleep(3)  # Wait for the page to load\n",
    "\n",
    "# Concatenate the dataframes in the list into a single dataframe\n",
    "all_floorsheet_data = pd.concat(all_floorsheet_data, ignore_index=True)\n",
    "date = str(all_floorsheet_data['Contract No.'].iloc[-1])[:8]\n",
    "date_format = pd.to_datetime(date, format='%Y%m%d').strftime('%m/%d/%Y')\n",
    "all_floorsheet_data[\"Date\"] = date_format\n",
    "all_floorsheet_data[\"Contract No.\"] = all_floorsheet_data[\"Contract No.\"].astype(str) + '\\t'\n",
    "# Save the floorsheet data to CSV\n",
    "# all_floorsheet_data.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Extract date from the last row of the 'Contract No.' column\n",
    "\n",
    "formatted_date = f\"{date[:4]}.{date[4:6]}.{date[6:]}\"\n",
    "# Save the data frame with date prefix in filename\n",
    "all_floorsheet_data.to_csv(f\"D:/Floorsheet/{formatted_date}.csv\", index=False)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n",
    "\n",
    "print(\"Floorsheet data extracted and savedÂ successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d2a7b984-0d29-4cbe-9a3c-6f0bcba4a4e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files combined, 'Date' column added, and saved as Parquet file at: D:/Floorsheet/df_combined_floorsheet.parquet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory containing the CSV files\n",
    "folder_path = 'D:/Floorsheet'\n",
    "\n",
    "# List to store DataFrames\n",
    "csv_files = [file for file in os.listdir(folder_path) if file.endswith('.csv')]\n",
    "\n",
    "# Combine all CSV files into one DataFrame\n",
    "df_combined_floorsheet = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(os.path.join(folder_path, file))\n",
    "        for file in csv_files\n",
    "    ],\n",
    "    ignore_index=True\n",
    ")\n",
    "\n",
    "# Add the \"Date\" column based on the first 8 characters of \"Contract No.\"\n",
    "# df_combined_floorsheet['Date'] = df_combined_floorsheet['Contract No.'].astype(str).str[:8]\n",
    "\n",
    "# Write the combined DataFrame to a Parquet file\n",
    "parquet_file_path = 'D:/Floorsheet/df_combined_floorsheet.parquet'\n",
    "df_combined_floorsheet.to_parquet(parquet_file_path)\n",
    "\n",
    "# Output the confirmation message\n",
    "print(f\"CSV files combined, 'Date' column added, and saved as Parquet file at: {parquet_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc888f34-0a36-4b10-8b84-927b30e180a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102861\n",
      "18081168\n",
      "10049654832.64\n"
     ]
    }
   ],
   "source": [
    "print(len(all_floorsheet_data))\n",
    "print(all_floorsheet_data[\"Quantity\"].sum())\n",
    "print(all_floorsheet_data[\"Amount (Rs)\"].sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
