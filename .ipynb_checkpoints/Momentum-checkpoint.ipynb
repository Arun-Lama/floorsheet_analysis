{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import dataframe_image as dfi\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\Dell\\Python Projects\\python modules')\n",
    "import os\n",
    "from docx2pdf import convert\n",
    "import webbrowser\n",
    "from read_write_google_sheet import read_google_sheet\n",
    "from Write_in_word import new_word_file, chart_to_word\n",
    "# Start the timer\n",
    "start_time = time.time()\n",
    "from ActiveCompanies import active_companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Commercial Banks\n",
      "Exported Commercial Banks chart to /Users/arun/Documents/Python Projects/Daily Momentum Report/Charts/Commercial Banks.png\n",
      "Microfinance\n",
      "Exported Microfinance chart to /Users/arun/Documents/Python Projects/Daily Momentum Report/Charts/Microfinance.png\n",
      "Non Life Insurance\n",
      "Exported Non Life Insurance chart to /Users/arun/Documents/Python Projects/Daily Momentum Report/Charts/Non Life Insurance.png\n",
      "Development Banks\n",
      "Exported Development Banks chart to /Users/arun/Documents/Python Projects/Daily Momentum Report/Charts/Development Banks.png\n",
      "Life Insurance\n",
      "Exported Life Insurance chart to /Users/arun/Documents/Python Projects/Daily Momentum Report/Charts/Life Insurance.png\n",
      "Hotels And Tourism\n",
      "Exported Hotels And Tourism chart to /Users/arun/Documents/Python Projects/Daily Momentum Report/Charts/Hotels And Tourism.png\n",
      "Finance\n",
      "Exported Finance chart to /Users/arun/Documents/Python Projects/Daily Momentum Report/Charts/Finance.png\n",
      "Hydro Power\n",
      "Exported Hydro Power chart to /Users/arun/Documents/Python Projects/Daily Momentum Report/Charts/Hydro Power.png\n",
      "Investment\n",
      "Exported Investment chart to /Users/arun/Documents/Python Projects/Daily Momentum Report/Charts/Investment.png\n",
      "Tradings\n",
      "Exported Tradings chart to /Users/arun/Documents/Python Projects/Daily Momentum Report/Charts/Tradings.png\n",
      "Others\n",
      "Exported Others chart to /Users/arun/Documents/Python Projects/Daily Momentum Report/Charts/Others.png\n",
      "Manufacturing And Processing\n",
      "Exported Manufacturing And Processing chart to /Users/arun/Documents/Python Projects/Daily Momentum Report/Charts/Manufacturing And Processing.png\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8987642300564517a9854c6abf0e4c18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "active_stocks = active_companies()\n",
    "\n",
    "\n",
    "# Read and process price history data\n",
    "adjusted_price = read_google_sheet(\"19qf_rGChHLvRGyb8WXHLlYNPCV8Xskozn626v6Ix_dw\")\n",
    "indices_data = adjusted_price\n",
    "indices_data['Date'] = pd.to_datetime(price_history['Date'])\n",
    "price_history = price_history.sort_values(by=['Date'], ascending=True)\n",
    "columns_except_symbol = price_history.columns.difference(['Ticker', 'Date'])\n",
    "price_history[columns_except_symbol] = price_history[columns_except_symbol].replace(',', '', regex=True).astype(float)\n",
    "price_history['sector'] = price_history['Ticker'].map(active_stocks.set_index('Symbol')['Sector'])\n",
    "# # Get the last trading day for \"Nepse Index\"\n",
    "latest_nepse = price_history[price_history['Ticker'] == 'NABIL'].iloc[-30:]\n",
    "last_trading_day = str(latest_nepse['Date'].iloc[-1]).split()[0]\n",
    "\n",
    "# # Create a new Word file with the last trading date\n",
    "new_word_file(last_trading_day)\n",
    "\n",
    "# # Get all unique industries\n",
    "industries = list(price_history['sector'].drop_duplicates().dropna())\n",
    "full_industry = industries\n",
    "\n",
    "# # Define the periods and their corresponding days for cumulative sum calculation\n",
    "periods = {\n",
    "    '1-D': 2, '2-D': 3, '3-D': 4, '4-D': 5,\n",
    "    '1-W': 6, '2-W': 11, '3-W': 16,\n",
    "    '1-M': 21, '2-M': 41, '3-M': 61,\n",
    "    '6-M': 121, '1-Y': 221, '2-Y': 442,\n",
    "    '3-Y': 660, '5-Y': 1101\n",
    "}\n",
    "\n",
    "# # Function to calculate cumulative sum returns\n",
    "def calculate_cumsum_returns(sector_data, periods):\n",
    "    cumsum_returns = {}\n",
    "    for period, days in periods.items():\n",
    "        returns = sector_data[-days:].copy()\n",
    "        for ticker in returns.columns:\n",
    "            if not pd.isna(returns[ticker].iloc[0]) and not pd.isna(returns[ticker].iloc[-1]):\n",
    "                returns.loc[:, ticker] = returns[ticker].ffill()\n",
    "        cumulative_returns = np.log(returns / returns.shift(1)).cumsum().iloc[-1]\n",
    "        \n",
    "        for ticker in returns.columns:\n",
    "            if pd.isna(returns[ticker].iloc[0]) or pd.isna(returns[ticker].iloc[-1]):\n",
    "                cumulative_returns[ticker] = np.nan\n",
    "        \n",
    "        cumsum_returns[period] = cumulative_returns\n",
    "    return cumsum_returns\n",
    "\n",
    "# Function to rank indices\n",
    "def rank_indices(cumsum_returns):\n",
    "    return {period: returns.rank(ascending=False, method='first') for period, returns in cumsum_returns.items()}\n",
    "\n",
    "# Function to style the dataframe for export\n",
    "def style_dataframe(df):\n",
    "    def custom_format(x):\n",
    "        return \"\" if pd.isna(x) else \"{:,.0f}\".format(x)\n",
    "\n",
    "    styled_df = df.style.map(\n",
    "        lambda x: 'background-color: white' if pd.isna(x) else '', subset=pd.IndexSlice[:, df.columns]\n",
    "    ).background_gradient(cmap='RdYlGn_r', axis=None).format(custom_format)\n",
    "\n",
    "    styled_df = styled_df.set_table_styles(\n",
    "        [{\n",
    "            'selector': 'table',\n",
    "            'props': [('font-size', '8pt'), ('width', 'auto')]\n",
    "        }, {\n",
    "            'selector': 'thead th',\n",
    "            'props': [('font-size', '8pt'), ('padding', '2px 5px')]\n",
    "        }, {\n",
    "            'selector': 'tbody td',\n",
    "            'props': [('font-size', '8pt'), ('padding', '2px 5px'), ('white-space', 'nowrap'), ('min-width', '10px')]\n",
    "        }]\n",
    "    ).set_properties(**{'text-align': 'center'})\n",
    "\n",
    "    return styled_df\n",
    "\n",
    "# Function to export styled dataframe as an image\n",
    "def export_to_image(styled_df, industry, export_dir='/Users/arun/Documents/Python Projects/Daily Momentum Report/Charts'):\n",
    "    try:\n",
    "        export_path = os.path.join(export_dir, f\"{industry}.png\")\n",
    "        dfi.export(styled_df, export_path, table_conversion='matplotlib')\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to export {industry} chart: {e}\")\n",
    "\n",
    "# Main loop to process each industry\n",
    "for industry in full_industry:\n",
    "    print(industry)\n",
    "    sector_wise_data = price_history[price_history['sector'] == industry]\n",
    "    sector_data = pd.pivot_table(sector_wise_data, values='Close', index=['Date'], columns=['Ticker'])\n",
    "    sector_data = sector_data.ffill()\n",
    "    \n",
    "    cumsum_returns = calculate_cumsum_returns(sector_data, periods)\n",
    "    ranked_indices = rank_indices(cumsum_returns)\n",
    "    \n",
    "    summary_df = pd.DataFrame(ranked_indices).copy()  # Ensure this is a copy\n",
    "\n",
    "    # Select the top 11 columns (specific periods)\n",
    "    momentums = summary_df.iloc[:, :11].copy()  # Explicit copy to avoid warnings\n",
    "\n",
    "    # Define weights for periods\n",
    "    selected_periods = ['1-D', '2-D', '3-D', '4-D', '1-W', '2-W', '3-W', '1-M', '2-M', '3-M', '6-M']\n",
    "    decay_rate = 0.85\n",
    "    weights = {period: decay_rate**i for i, period in enumerate(selected_periods)}\n",
    "    weight_sum = sum(weights.values())\n",
    "    weights = {k: v / weight_sum for k, v in weights.items()}\n",
    "\n",
    "    # Calculate weighted scores\n",
    "    momentums.loc[:, 'Weighted_Score'] = momentums.apply(\n",
    "        lambda row: sum(row[period] * weights[period] for period in weights if period in row),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Normalize scores\n",
    "    min_score = momentums['Weighted_Score'].min()\n",
    "    max_score = momentums['Weighted_Score'].max()\n",
    "    momentums.loc[:, 'Final'] = 1 + ((momentums['Weighted_Score'] - min_score) / (max_score - min_score)) * 9\n",
    "\n",
    "    # Sort and keep top 20\n",
    "    momentums = momentums.sort_values(by='Weighted_Score', ascending=True).iloc[:20].copy()\n",
    "    momentums = momentums.drop(columns=['Weighted_Score'])\n",
    "\n",
    "\n",
    "    # Style and export the dataframe\n",
    "    styled_df = style_dataframe(momentums)\n",
    "    export_to_image(styled_df, industry)\n",
    "\n",
    "    # Add the chart to the Word document\n",
    "    chart_to_word(last_trading_day, '', f\"{industry}.png\", '', '', '', '', '')\n",
    "\n",
    "# Convert Word document to PDF and open it\n",
    "convert(f'/Users/arun/Documents/Python Projects/Daily Momentum Report/Report as on {last_trading_day}.docx', f'/Users/arun/Documents/Python Projects/Daily Momentum Report/Momentum Report as on {last_trading_day}.pdf')\n",
    "webbrowser.open_new(f'/Users/arun/Documents/Python Projects/Daily Momentum Report/Momentum Report as on {last_trading_day}.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_data = read_google_sheet(\"1VvJsBXRGZ7sKRhGeHr-DCjnESjiYWsVm-A0ZIYG6en0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m indices_data \u001b[38;5;241m=\u001b[39m indices_data\u001b[38;5;241m.\u001b[39msort_values(by\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m], ascending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m columns_except_symbol \u001b[38;5;241m=\u001b[39m indices_data\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mdifference([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTicker\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 5\u001b[0m indices_data[columns_except_symbol] \u001b[38;5;241m=\u001b[39m indices_data[columns_except_symbol]\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m      6\u001b[0m indices_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msector\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m indices_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTicker\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap(active_stocks\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSymbol\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSector\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6639\u001b[0m     ]\n\u001b[1;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mastype(dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m    431\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    432\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    433\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    434\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    435\u001b[0m     using_cow\u001b[38;5;241m=\u001b[39musing_copy_on_write(),\n\u001b[1;32m    436\u001b[0m )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(b, f)(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m astype_array_safe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m astype_array(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m _astype_nansafe(values, dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "indices_data['Date'] = pd.to_datetime(indices_data['Date'], format='mixed')\n",
    "\n",
    "indices_data = indices_data.sort_values(by=['Date'], ascending=True)\n",
    "columns_except_symbol = indices_data.columns.difference(['Ticker', 'Date'])\n",
    "indices_data[columns_except_symbol] = indices_data[columns_except_symbol].replace(',', '', regex=True).astype(float)\n",
    "indices_data['sector'] = indices_data['Ticker'].map(active_stocks.set_index('Symbol')['Sector'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
